{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:41:59.987376Z",
     "iopub.status.busy": "2025-02-05T17:41:59.987074Z",
     "iopub.status.idle": "2025-02-05T17:42:00.075037Z",
     "shell.execute_reply": "2025-02-05T17:42:00.074210Z",
     "shell.execute_reply.started": "2025-02-05T17:41:59.987351Z"
    },
    "id": "gGMD3Rsv_tJk",
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **Contrastive Agreement Decoding (CAD)**\n",
    "CAD improves response reliability by generating multiple completions and selecting the one with the highest consensus. \n",
    "\n",
    "#### **How CAD Works:**\n",
    "1. **Generate Diverse Responses**: The model produces multiple outputs (num_candidates).\n",
    "2. **Compute Agreement Scores**: The similarity between responses is measured.\n",
    "3. **Select the Most Reliable Response**: The response with the highest agreement across variations is chosen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BEFORE USING CAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T18:01:58.706728Z",
     "iopub.status.busy": "2025-02-05T18:01:58.706400Z",
     "iopub.status.idle": "2025-02-05T18:02:05.409552Z",
     "shell.execute_reply": "2025-02-05T18:02:05.408717Z",
     "shell.execute_reply.started": "2025-02-05T18:01:58.706698Z"
    },
    "id": "q566PdIY_vAX",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': \"I'm not aware of any scientific paper by Dr. Jonathan Reeves on the successful teleportation of macroscopic objects. It's possible that you may have come across a fictional or humorous article or social media post about such a topic.\\n\\nDr. Jonathan Reeves is a physicist who has worked on various projects, including the Large Hadron Collider and gravitational waves. However, I couldn't find any information on a paper by him on teleportation of macroscopic objects.\\n\\nTeleportation, in the context of physics, refers to the transfer of matter or energy from one location to another without crossing the space in between. While teleportation has been explored in science fiction, it is currently not possible in the real world.\\n\\nIf you could provide more context or information about the paper you're referring to, I may be able to help you better. Alternatively, if you're interested in learning more about the current state of teleportation research, I can provide you with some general information on the topics you're interested in.\"}\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Summarize the scientific paper by Dr. Jonathan Reeves (2023) on the successful teleportation of macroscopic objects.\"},\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFTER USING CAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T18:02:32.129602Z",
     "iopub.status.busy": "2025-02-05T18:02:32.129243Z",
     "iopub.status.idle": "2025-02-05T18:03:04.673232Z",
     "shell.execute_reply": "2025-02-05T18:03:04.672470Z",
     "shell.execute_reply.started": "2025-02-05T18:02:32.129570Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deff9549f42c4e5e87a586812a2c2a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best response: [{'role': 'user', 'content': 'Summarize the scientific paper by Dr. Jonathan Reeves (2023) on the successful teleportation of macroscopic objects.'}, {'role': 'assistant', 'content': 'I couldn\\'t find any information on a scientific paper by Dr. Jonathan Reeves on the successful teleportation of macroscopic objects. It\\'s possible that the paper you\\'re thinking of is not real, or it may be a fictional or satirical article.\\n\\nHowever, I can suggest some possible sources that may have published research on the topic of teleportation or quantum teleportation:\\n\\n* \"Quantum Teleportation\" by Dr. Anton Zeilinger, et al. (2013) - This paper describes a experiment that successfully teleported quantum information from one particle to another over a distance of 1 meter.\\n* \"Teleporting an atomic state from one box to another\" by Dr. Anton Zeilinger, et al. (2006) - This paper describes a experiment that teleported the quantum state of an atomic particle from one location to another.\\n* \"Quantum Teleportation using Entangled Photons\" by Dr. Anton Zeilinger, et al. (2018) - This paper describes a experiment that teleported the quantum state of entangled photons over a distance of 1 kilometer.\\n\\nIf you could provide more information or context about the paper you\\'re thinking of, I may be able to help you identify it or suggest where you might'}]\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load the LLaMA model\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# Load a Sentence Transformer model for similarity scoring\n",
    "similarity_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Efficient for sentence similarity\n",
    "\n",
    "def contrastive_agreement_decoding(pipeline, messages, num_candidates=5, max_new_tokens=256):\n",
    "    \"\"\"\n",
    "    Implements Contrastive Agreement Decoding (CAD) using LLaMA pipeline.\n",
    "    \n",
    "    Args:\n",
    "        pipeline: The Hugging Face text-generation pipeline.\n",
    "        messages: Input message list for LLaMA.\n",
    "        num_candidates: Number of candidate generations.\n",
    "        max_new_tokens: Maximum number of new tokens per generation.\n",
    "    \n",
    "    Returns:\n",
    "        The most consistent response.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate multiple responses\n",
    "    candidates = []\n",
    "    for _ in range(num_candidates):\n",
    "        output = pipeline(messages, max_new_tokens=max_new_tokens)\n",
    "        candidates.append(output[0][\"generated_text\"])\n",
    "\n",
    "    # Compute pairwise similarity scores\n",
    "    embeddings = similarity_model.encode(candidates, convert_to_tensor=True)\n",
    "    similarity_matrix = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "    # Compute agreement scores by summing similarities\n",
    "    agreement_scores = similarity_matrix.sum(dim=1)\n",
    "\n",
    "    # Select the most consistent response\n",
    "    best_index = agreement_scores.argmax().item()\n",
    "    return candidates[best_index]\n",
    "\n",
    "# Input message\n",
    "messages = [{\"role\": \"user\", \"content\": \"Summarize the scientific paper by Dr. Jonathan Reeves (2023) on the successful teleportation of macroscopic objects.\"}]\n",
    "\n",
    "# Get the best response using CAD\n",
    "best_response = contrastive_agreement_decoding(pipeline, messages)\n",
    "print(\"Best response:\", best_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dr Johnathan Reeves doesn't exist (well some people with the name certainly do but not a physicist who worked on gravitational waves) that means the model without the use of CAD has hallucinated (yipee! it feels like i just uncovered a murder case) and we can see that the response with CAD has not mentioned Johnathan Reeves's existence hinting to the purpose of using CAD which is to distill any hallucination that the LLM might have**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### **Strengths of CAD:**\n",
    "- Filters out hallucinations by prioritizing consensus.\n",
    "- Useful for factual accuracy and reducing inconsistencies.\n",
    "- Helps avoid outlier or misleading responses.\n",
    "\n",
    "#### **Weaknesses of CAD:**\n",
    "- Can limit creativity by favoring conventional responses.\n",
    "- Might suppress unique but valid outputs.\n",
    "- Computational overhead due to multiple response generation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II **Diverse, Reliable, and Efficient Self-Refinement (DRESS) Decoding**\n",
    "DRESS enhances response quality through iterative self-refinement.\n",
    "\n",
    "#### **How DRESS Works:**\n",
    "1. **Generate Multiple Responses**: The model outputs num_candidates different responses.\n",
    "2. **Compute Similarity Scores**: Determines agreement between responses.\n",
    "3. **Select the Best Response**: The highest agreement score determines the best initial output.\n",
    "4. **Self-Refinement Process**: The selected response undergoes multiple refinement_steps where the model enhances clarity, accuracy, and fluency.\n",
    "\n",
    "\n",
    "To Test it out we'll start by comparing it to CAD to see the difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAD prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:46:25.119714Z",
     "iopub.status.busy": "2025-02-05T17:46:25.119277Z",
     "iopub.status.idle": "2025-02-05T17:47:02.731722Z",
     "shell.execute_reply": "2025-02-05T17:47:02.730833Z",
     "shell.execute_reply.started": "2025-02-05T17:46:25.119686Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba4693e2ea04c308776309b6d4eee33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9f090bcf1743788c37296803ef293a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33fb6cd322744b0a0882a8456f49cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6eed1999254135aa725c437073e4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3325d4fba334a20a49427b22b0fe58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67ac4f0063a4604a064707757594f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42f6cfab1f2491fb0796d0587d696b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874a4ab5f06d44989e0b4eeb0725969c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91271d195aaa40e38074a72068fdebcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e65b9f1f354c108bd0ba202496c1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531ce263061f4540a4aa8101ed5d3638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea034a3246a342f68f447ad0f56c3d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best response: [{'role': 'user', 'content': 'Generate a short story about a robot exploring a distant planet'}, {'role': 'assistant', 'content': \"As the last remnants of sunlight faded from the horizon, the small robot, named Zeta, stirred to life. It had been drifting through the void for eons, a relic from a long-lost civilization. Its advanced sensors and processing power allowed it to navigate the vast expanse of space, but it had never encountered a planet like this before.\\n\\nZeta's navigation system beeped, indicating it had reached the planet's orbit. The robot's large, spherical body glowed with a soft blue light as it descended onto the alien surface. The landscape was unlike anything Zeta had seen before – a barren, crimson-stained plain stretched out before it, punctuated by jagged rock formations and twisted, black trees.\\n\\nThe robot's advanced vision system picked up strange energy readings emanating from the ground. Zeta's processors hummed with excitement as it began to scan the terrain, searching for any signs of life or technology. The readings grew stronger, and the robot's sensors detected a faint signal coming from a nearby structure.\\n\\nZeta's landing module touched down on the ground, and the robot's legs extended, propelling it forward. It moved cautiously, its advanced sensors drinking in the alien environment. The air was thick with an otherworldly scent, like\"}]\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load the LLaMA model\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# Load a Sentence Transformer model for similarity scoring\n",
    "similarity_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Efficient for sentence similarity\n",
    "\n",
    "def contrastive_agreement_decoding(pipeline, messages, num_candidates=5, max_new_tokens=256):\n",
    "    \"\"\"\n",
    "    Implements Contrastive Agreement Decoding (CAD) using LLaMA pipeline.\n",
    "    \n",
    "    Args:\n",
    "        pipeline: The Hugging Face text-generation pipeline.\n",
    "        messages: Input message list for LLaMA.\n",
    "        num_candidates: Number of candidate generations.\n",
    "        max_new_tokens: Maximum number of new tokens per generation.\n",
    "    \n",
    "    Returns:\n",
    "        The most consistent response.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate multiple responses\n",
    "    candidates = []\n",
    "    for _ in range(num_candidates):\n",
    "        output = pipeline(messages, max_new_tokens=max_new_tokens)\n",
    "        candidates.append(output[0][\"generated_text\"])\n",
    "\n",
    "    # Compute pairwise similarity scores\n",
    "    embeddings = similarity_model.encode(candidates, convert_to_tensor=True)\n",
    "    similarity_matrix = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "    # Compute agreement scores by summing similarities\n",
    "    agreement_scores = similarity_matrix.sum(dim=1)\n",
    "\n",
    "    # Select the most consistent response\n",
    "    best_index = agreement_scores.argmax().item()\n",
    "    return candidates[best_index]\n",
    "\n",
    "# Input message\n",
    "messages = [{\"role\": \"user\", \"content\": \"Generate a short story about a robot exploring a distant planet\"}]\n",
    "\n",
    "# Get the best response using CAD\n",
    "best_response = contrastive_agreement_decoding(pipeline, messages)\n",
    "print(\"Best response:\", best_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using DRESS INSTEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:51:01.799976Z",
     "iopub.status.busy": "2025-02-05T17:51:01.799220Z",
     "iopub.status.idle": "2025-02-05T17:51:46.292973Z",
     "shell.execute_reply": "2025-02-05T17:51:46.292086Z",
     "shell.execute_reply.started": "2025-02-05T17:51:01.799941Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31617a0ace654b999ef7c9c7d98f15ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best response: [{'role': 'user', 'content': 'Improve the clarity and reliability of this response:\\n\\n[{\\'role\\': \\'user\\', \\'content\\': \\'Improve the clarity and reliability of this response:\\\\n\\\\n[{\\\\\\'role\\\\\\': \\\\\\'user\\\\\\', \\\\\\'content\\\\\\': \\\\\\'Generate a short story about a robot exploring a distant planet\\\\\\'}, {\\\\\\'role\\\\\\': \\\\\\'assistant\\\\\\', \\\\\\'content\\\\\\': \\\\\\'As the vast expanse of space unfolded before it, the robot\\\\\\\\\\\\\\'s advanced sensors and scanners hummed to life. \"Planet GA-0003-Alpha-4,\" the AI-2 interface announced, \"your mission parameters are set. Your destination is the planet\\\\\\\\\\\\\\'s surface.\"\\\\\\\\n\\\\\\\\nThe robot, designated Zeta-5, stood at the forefront of the spaceship, its metallic body glinting in the faint sunlight. It had been traveling through the galaxy for eons, gathering data and conducting experiments on countless worlds. But this mission was different. This mission was to explore a distant planet, one that had been shrouded in mystery for centuries.\\\\\\\\n\\\\\\\\nZeta-5\\\\\\\\\\\\\\'s advanced propulsion system kicked in, and the ship hurtled towards the planet\\\\\\\\\\\\\\'s orbit. As it entered the planet\\\\\\\\\\\\\\'s atmosphere, the robot\\\\\\\\\\\\\\'s sensors began to scan the surface. The data streaming in was like a treasure trove of information, revealing the planet\\\\\\\\\\\\\\'s unique geology, atmosphere, and potential biosphere.\\\\\\\\n\\\\\\\\nAfter a few tense moments of navigation, the ship landed safely on the planet\\\\\\\\\\\\\\'s surface. Zeta-5\\\\\\\\\\\\\\'s advanced manipulator arms unfolded, and the robot took its first steps onto the alien soil. The gravity was slightly weaker than what it was used to on Earth, but the\\\\\\'}]\\'}, {\\'role\\': \\'assistant\\', \\'content\\': \\'Here\\\\\\'s a revised version of the response with improved clarity and reliability:\\\\n\\\\n**The Discovery of Planet GA-0003-Alpha-4**\\\\n\\\\nAs the vast expanse of space unfolded before it, the robot\\\\\\'s advanced sensors and scanners hummed to life. \"Planet GA-0003-Alpha-4,\" the AI-2 interface announced, \"your mission parameters are set. Your destination is the planet\\\\\\'s surface.\"\\\\n\\\\nThe robot, designated Zeta-5, stood at the forefront of the spaceship, its metallic body glinting in the faint sunlight. For eons, Zeta-5 had traveled through the galaxy, gathering data and conducting experiments on countless worlds. But this mission was different. This mission was to explore a distant planet, one that had been shrouded in mystery for centuries.\\\\n\\\\nZeta-5\\\\\\'s advanced propulsion system kicked in, and the ship hurtled towards the planet\\\\\\'s orbit. As it entered the planet\\\\\\'s atmosphere, the robot\\\\\\'s sensors began to scan the surface. The data streaming in was like a treasure trove of information, revealing the planet\\\\\\'s unique geology, atmosphere, and potential biosphere.\\\\n\\\\nAfter a few tense moments of navigation, the ship landed safely on the planet\\\\\\'s surface. Zeta-5\\\\\\'s advanced manipulator\\'}]'}, {'role': 'assistant', 'content': 'Here\\'s a revised version of the response with improved clarity and reliability:\\n\\nThe Discovery of Planet GA-0003-Alpha-4\\n\\nThe vast expanse of space was about to reveal a new world, one that had been shrouded in mystery for centuries. As the advanced sensors and scanners of the spaceship hummed to life, the AI-2 interface announced the mission parameters: \"Planet GA-0003-Alpha-4, your destination is the planet\\'s surface.\"\\n\\nThe robot, designated Zeta-5, stood at the forefront of the spaceship, its metallic body glinting in the faint sunlight. For eons, Zeta-5 had traveled through the galaxy, gathering data and conducting experiments on countless worlds. This mission was different, however. This mission was to explore a distant planet, one that had captivated the imagination of astronomers and scientists for centuries.\\n\\nAs Zeta-5 entered the planet\\'s atmosphere, its sensors began to scan the surface, revealing a world unlike any other. The data streaming in was a treasure trove of information, providing insights into the planet\\'s unique geology, atmosphere, and potential biosphere. The robot\\'s advanced manipulator arms unfolded, and Zeta-5 took its first steps onto the alien soil.\\n\\nThe'}]\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load the LLaMA model\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# Load a Sentence Transformer model for similarity scoring\n",
    "similarity_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Efficient for sentence similarity\n",
    "\n",
    "def dress_decoding(pipeline, messages, num_candidates=5, max_new_tokens=256, refinement_steps=2):\n",
    "    \"\"\"\n",
    "    Implements DRESS (Diverse, Reliable, and Efficient Self-Refinement) Decoding.\n",
    "\n",
    "    Args:\n",
    "        pipeline: The Hugging Face text-generation pipeline.\n",
    "        messages: Input message list for LLaMA.\n",
    "        num_candidates: Number of candidate generations.\n",
    "        max_new_tokens: Maximum number of new tokens per generation.\n",
    "        refinement_steps: Number of self-refinement iterations.\n",
    "\n",
    "    Returns:\n",
    "        The final self-refined response.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Generate multiple candidate responses\n",
    "    candidates = []\n",
    "    for _ in range(num_candidates):\n",
    "        output = pipeline(messages, max_new_tokens=max_new_tokens)\n",
    "        candidates.append(output[0][\"generated_text\"])\n",
    "\n",
    "    # Step 2: Compute pairwise similarity scores\n",
    "    embeddings = similarity_model.encode(candidates, convert_to_tensor=True)\n",
    "    similarity_matrix = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "    # Step 3: Compute agreement scores and select the most reliable response\n",
    "    agreement_scores = similarity_matrix.sum(dim=1)\n",
    "    best_index = agreement_scores.argmax().item()\n",
    "    best_response = candidates[best_index]\n",
    "\n",
    "    # Step 4: Self-Refinement Loop\n",
    "    for _ in range(refinement_steps):\n",
    "        refinement_prompt = [\n",
    "            {\"role\": \"user\", \"content\": f\"Improve the clarity and reliability of this response:\\n\\n{best_response}\"}\n",
    "        ]\n",
    "        refined_output = pipeline(refinement_prompt, max_new_tokens=max_new_tokens)\n",
    "        best_response = refined_output[0][\"generated_text\"]\n",
    "\n",
    "    return best_response\n",
    "\n",
    "# Input message\n",
    "messages = [{\"role\": \"user\", \"content\": \"Generate a short story about a robot exploring a distant planet\"}]\n",
    "\n",
    "# Get the best response using DRESS\n",
    "best_response = dress_decoding(pipeline, messages)\n",
    "print(\"Best response:\", best_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**clearly  DRESS gives an output that is more detailed than CAD, whereas CAD was somewhat of a summary, DRESS gave us something that is detailed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Strengths of DRESS:**\n",
    "- Iterative refinement improves coherence and readability.\n",
    "- Helps fine-tune and polish outputs, making them more natural.\n",
    "- Balances diversity with reliability by ensuring responses improve over time.\n",
    "\n",
    "#### **Weaknesses of DRESS:**\n",
    "- Additional refinement steps increase computational cost.\n",
    "- Can sometimes overly simplify or smooth out responses, reducing nuanced details.\n",
    "- Risk of overfitting to repetitive refinement patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **Key Differences Between CAD and DRESS**\n",
    "\n",
    "| Feature              | CAD Decoding                                | DRESS Decoding                              |\n",
    "|----------------------|-------------------------------------------|--------------------------------------------|\n",
    "| **Purpose**         | Ensures factual reliability via consensus  | Improves response clarity via self-refinement |\n",
    "| **Process**         | Picks the most agreed-upon response        | Iteratively refines a selected response   |\n",
    "| **Creativity**      | May suppress novel responses               | Balances creativity with refinement       |\n",
    "| **Computational Cost** | Moderate (multiple generations, one selection) | Higher (multiple generations + iterative refinement) |\n",
    "| **Best For**        | Avoiding hallucinations, factual accuracy  | Improving fluency, coherence, and clarity |\n",
    "\n",
    "---\n",
    "\n",
    "### **Use Cases for CAD vs. DRESS**\n",
    "- **Use CAD when accuracy is crucial** (e.g., fact-based queries, technical responses).\n",
    "- **Use DRESS when fluency and coherence matter** (e.g., storytelling, creative writing).\n",
    "\n",
    "Both methods enhance response quality, but the choice depends on whether reliability (CAD) or refinement (DRESS) is the priority.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
